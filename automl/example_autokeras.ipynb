{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AMyQ6XnvLNC"
      },
      "source": [
        "Installing the autokesa python package\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7mZS9Lptyk2",
        "outputId": "9afda188-189d-4f50-9cf8-e54cfebf97a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autokeras\n",
            "  Downloading autokeras-2.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from autokeras) (24.1)\n",
            "Collecting keras-tuner>=1.4.0 (from autokeras)\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting keras-nlp>=0.8.0 (from autokeras)\n",
            "  Downloading keras_nlp-0.15.1-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from autokeras) (3.4.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from autokeras) (0.1.8)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->autokeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->autokeras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->autokeras) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->autokeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->autokeras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->autokeras) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->autokeras) (0.4.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras-nlp>=0.8.0->autokeras) (2024.9.11)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras-nlp>=0.8.0->autokeras) (0.3.0)\n",
            "Collecting tensorflow-text (from keras-nlp>=0.8.0->autokeras)\n",
            "  Downloading tensorflow_text-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner>=1.4.0->autokeras) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner>=1.4.0->autokeras)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras-nlp>=0.8.0->autokeras) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=3.0.0->autokeras) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner>=1.4.0->autokeras) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner>=1.4.0->autokeras) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner>=1.4.0->autokeras) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner>=1.4.0->autokeras) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->autokeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->autokeras) (2.18.0)\n",
            "Requirement already satisfied: tensorflow<2.18,>=2.17.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->keras-nlp>=0.8.0->autokeras) (2.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->autokeras) (0.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (2.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (2.17.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (0.44.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17.0->tensorflow-text->keras-nlp>=0.8.0->autokeras) (2.1.5)\n",
            "Downloading autokeras-2.0.0-py3-none-any.whl (122 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.7/122.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras_nlp-0.15.1-py3-none-any.whl (548 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.4/548.4 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Downloading tensorflow_text-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kt-legacy, keras-tuner, tensorflow-text, keras-nlp, autokeras\n",
            "Successfully installed autokeras-2.0.0 keras-nlp-0.15.1 keras-tuner-1.4.7 kt-legacy-1.0.5 tensorflow-text-2.17.0\n"
          ]
        }
      ],
      "source": [
        "%pip install autokeras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpgDIlgIvtgV"
      },
      "source": [
        "Importing used packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ijK1rfQbvtN5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import keras\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import load_files\n",
        "\n",
        "import autokeras as ak"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zUSPEAgv6dJ"
      },
      "source": [
        "Importing the dataset. <br>\n",
        "In this example we use a dataset for binary sentiment classification. The dataset contains a set of 25,000 highly polar movie reviews for training, and 25,000 for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vc8_Cb_4v_zC",
        "outputId": "a38b07a6-7fa9-49eb-9e9a-5d02a9d4d259",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "\u001b[1m84125825/84125825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "dataset = keras.utils.get_file(\n",
        "    fname=\"aclImdb.tar.gz\",\n",
        "    origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
        "    extract=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xx3rMyVuwB5U"
      },
      "source": [
        "For reducing the execution time, we use only the first 100 rows of the train and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vxk5bcEDwODV",
        "outputId": "dea73b94-7f5b-4909-ea7e-72d378543550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100,)\n",
            "(100,)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# set path to dataset\n",
        "IMDB_DATADIR = os.path.join(os.path.dirname(dataset), \"aclImdb\")\n",
        "\n",
        "classes = [\"pos\", \"neg\"]\n",
        "train_data = load_files(\n",
        "    os.path.join(IMDB_DATADIR, \"train\"), shuffle=True, categories=classes\n",
        ")\n",
        "test_data = load_files(\n",
        "    os.path.join(IMDB_DATADIR, \"test\"), shuffle=False, categories=classes\n",
        ")\n",
        "\n",
        "x_train = np.array(train_data.data)[:100]\n",
        "y_train = np.array(train_data.target)[:100]\n",
        "x_test = np.array(test_data.data)[:100]\n",
        "y_test = np.array(test_data.target)[:100]\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF0d3i1bwRaS"
      },
      "source": [
        "Set up the TextClassifier. <br>\n",
        "The ***max_trials*** parameter sets the maximum number of different Keras Models to try. The search may finish before reaching the *max_trials*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8hQYsQeuwPNH"
      },
      "outputs": [],
      "source": [
        "clf = ak.TextClassifier(overwrite=True, max_trials=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFYg055F59D1"
      },
      "source": [
        "Providing the training data to the model.\n",
        "\n",
        "The ***fit*** function searches for the best model and hyperparameters for the AutoModel based on the validation performance. It returns the best model found.\n",
        "\n",
        "The ***epochs*** parameter defines the number of epochs to train each model during the search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ds8FW-L86EX_",
        "outputId": "67fe396d-fa63-4b66-cd9b-4bce67161228"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_base_en_uncased/2/download/config.json...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 510/510 [00:00<00:00, 1.00MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_base_en_uncased/2/download/tokenizer.json...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 547/547 [00:00<00:00, 519kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_base_en_uncased/2/download/assets/tokenizer/vocabulary.txt...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 226k/226k [00:00<00:00, 6.84MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_base_en_uncased/2/download/model.weights.h5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 418M/418M [00:06<00:00, 64.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Search: Running Trial #1\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0                 |0                 |classification_head_1/dropout\n",
            "adam_weight_decay |adam_weight_decay |optimizer\n",
            "2e-05             |2e-05             |learning_rate\n",
            "512               |512               |text_block_1/bert_block_1/max_sequence_length\n",
            "\n",
            "Epoch 1/20\n",
            "\u001b[1m 4/40\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:02\u001b[0m 17s/step - accuracy: 0.4688 - loss: 0.8144"
          ]
        }
      ],
      "source": [
        "clf.fit(x_train, y_train, epochs=20, batch_size=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09Mtox_G7iYJ"
      },
      "source": [
        "Predicting and evaluating <br>\n",
        "\n",
        "Now the ***clf*** variable contains the best model found. So, we can classify the test dataset and assess the model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ertotxfL6GLA"
      },
      "outputs": [],
      "source": [
        "predicted_y = clf.predict(x_test)\n",
        "print(clf.evaluate(x_test, y_test))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}